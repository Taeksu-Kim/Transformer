{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY9gIZoPREnL",
        "outputId": "ea0e0908-e5e3-4d02-9bf5-95ac990d93db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.7 in /usr/local/lib/python3.7/dist-packages (4.7.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (4.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.7 torchinfo rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYucaGAGRmJX",
        "outputId": "64c86469-ce3b-4869-c407-d07d6c84fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Transformer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Taeksu-Kim/Transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHZ0wWoTRmLv",
        "outputId": "8fe4b417-27e4-4558-d459-55b57ebd01ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Transformer/PyTorch\n"
          ]
        }
      ],
      "source": [
        "cd Transformer/PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUltP3SVSDN2",
        "outputId": "92eb011f-d1ac-4896-fa88-348fbf5793bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Chatbot_data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "soWE65AlSDP9"
      },
      "outputs": [],
      "source": [
        "# common\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchinfo import summary\n",
        "from rouge import Rouge\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# custom\n",
        "from transformer import Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kOxo_8pmc0tI"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed = 42\n",
        "\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OyV4zC-teD-Y"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 300\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-2\n",
        "batch_size = 64\n",
        "\n",
        "gradient_scaler = True\n",
        "# use_lr_scheduler = False\n",
        "\n",
        "early_stopping_patience = 10\n",
        "\n",
        "save_name = 'tft_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j8H6qx8HZW4Y"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./Chatbot_data/ChatbotData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vcy_7abBaWGX"
      },
      "outputs": [],
      "source": [
        "model_path = \"monologg/kobigbird-bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hBob5L-SZW7Q"
      },
      "outputs": [],
      "source": [
        "def cal_token_len(text, tokenizer):\n",
        "  return len(tokenizer.encode(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsFzl3chZW93",
        "outputId": "b73968b5-6c36-4ab5-9cbe-ff07bd02eedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11823/11823 [00:04<00:00, 2944.68it/s]\n"
          ]
        }
      ],
      "source": [
        "df['enc_token_len'] = [ cal_token_len(df.iloc[i]['Q'], tokenizer) for i in tqdm(range(df.shape[0])) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx6dRe2uaFj-",
        "outputId": "dd99f13b-3fd0-46ee-bf9f-04483f6ee92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11823/11823 [00:05<00:00, 2286.50it/s]\n"
          ]
        }
      ],
      "source": [
        "df['dec_token_len'] = [ cal_token_len(df.iloc[i]['A'], tokenizer) for i in tqdm(range(df.shape[0])) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RdbgeiIOaABF",
        "outputId": "65969eaa-dcdf-4b69-9e34-19c645491290"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label  enc_token_len  dec_token_len\n",
              "0           12시 땡!   하루가 또 가네요.      0              6              8\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0              8              6\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0             11              8\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0             12              8\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0              6              9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-213bee00-c214-4faf-a59d-bea47ecde481\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "      <th>enc_token_len</th>\n",
              "      <th>dec_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-213bee00-c214-4faf-a59d-bea47ecde481')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-213bee00-c214-4faf-a59d-bea47ecde481 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-213bee00-c214-4faf-a59d-bea47ecde481');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaGKGsU4ZXAo",
        "outputId": "c2653c01-6bbf-4d2a-f1bc-360bba88c15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% length : 16.0\n",
            "98% length : 19.0\n",
            "99% length : 20.0\n",
            "100% length : 30.0\n"
          ]
        }
      ],
      "source": [
        "tar_per_list = [95,98,99,100]\n",
        "tar_col = df['enc_token_len']\n",
        "\n",
        "for i in tar_per_list:\n",
        "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Jz98uJmWbtMQ"
      },
      "outputs": [],
      "source": [
        "max_enc_len = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hcjVQjZXDP",
        "outputId": "fd91d9cd-9dd8-4132-8ba8-7be19974b045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% length : 18.0\n",
            "98% length : 20.0\n",
            "99% length : 23.0\n",
            "100% length : 42.0\n"
          ]
        }
      ],
      "source": [
        "tar_col = df['dec_token_len']\n",
        "\n",
        "for i in tar_per_list:\n",
        "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uAh_OP14ZXF5"
      },
      "outputs": [],
      "source": [
        "max_dec_len = 26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "79qHoTj_b45G"
      },
      "outputs": [],
      "source": [
        "df = df[(df['enc_token_len']<=max_enc_len)&(df['dec_token_len']<=max_dec_len)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iCEH0pGxb47l",
        "outputId": "81b9c54e-9676-4b5e-da10-3833abd00af8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label  enc_token_len  dec_token_len\n",
              "0           12시 땡!   하루가 또 가네요.      0              6              8\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0              8              6\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0             11              8\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0             12              8\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0              6              9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ece5e01d-b4c0-48cd-8830-6533be05f210\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "      <th>enc_token_len</th>\n",
              "      <th>dec_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ece5e01d-b4c0-48cd-8830-6533be05f210')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ece5e01d-b4c0-48cd-8830-6533be05f210 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ece5e01d-b4c0-48cd-8830-6533be05f210');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C-oykEIycXwS"
      },
      "outputs": [],
      "source": [
        "train, valid =  train_test_split(df, test_size=0.05, random_state=seed, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9TnBv06gTrHE"
      },
      "outputs": [],
      "source": [
        "def mk_token_inputs(text, max_seq_len, mode='encoder'):\n",
        "    input_ids = tokenizer.encode(text,max_length=max_seq_len, padding='max_length')\n",
        "    \n",
        "    if mode == 'decoder':\n",
        "      cls_idx = input_ids.index(tokenizer.cls_token_id)\n",
        "      sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "      input_ids[cls_idx] = tokenizer.bos_token_id\n",
        "      input_ids[sep_idx] = tokenizer.eos_token_id\n",
        "\n",
        "    return torch.tensor(input_ids, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EHnr6x_4bk0W"
      },
      "outputs": [],
      "source": [
        "class chatbot_dataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, enc_max_len, dec_max_len):\n",
        "    self.df = df\n",
        "    self.enc_max_len = enc_max_len\n",
        "    self.dec_max_len = dec_max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return {'enc_inputs' : mk_token_inputs(self.df['Q'].iloc[index], self.enc_max_len),\n",
        "            'dec_inputs' : mk_token_inputs(self.df['A'].iloc[index], self.dec_max_len, mode='decoder'),\n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Uee1UbQRbthI"
      },
      "outputs": [],
      "source": [
        "train_dataset = chatbot_dataset(train, max_enc_len, max_dec_len+1)\n",
        "valid_dataset = chatbot_dataset(valid, max_enc_len, max_dec_len+1)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "woHDPphObk21"
      },
      "outputs": [],
      "source": [
        "for i, batch in enumerate(train_dataloader):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "00eqSz3Bbkpm"
      },
      "outputs": [],
      "source": [
        "# Config Class\n",
        "# dict class를 json으로 바꿔서 confg.arg 와 같이 사용할 수 있게 만드는 class\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dWOa15pObksU"
      },
      "outputs": [],
      "source": [
        "config_dict = {\n",
        "    'vocab_size' : tokenizer.vocab_size,\n",
        "    'd_model' : 256,\n",
        "    'max_enc_len' : max_enc_len,\n",
        "    'max_dec_len' : max_dec_len,\n",
        "    'pad_id' : tokenizer.pad_token_id,\n",
        "    'bos_id' : tokenizer.bos_token_id,\n",
        "    'eos_id' : tokenizer.eos_token_id,\n",
        "    'use_decoder' : True,\n",
        "    'init_std' : 2e-2,\n",
        "    'norm_eps' : 1e-12, \n",
        "    'drop_out_raito' : 0.1,\n",
        "    'num_enc_layers' : 3,\n",
        "    'num_dec_layers' : 3,\n",
        "    'num_att_heads' : 4,\n",
        "    'feed_forward_dim' : 1024,\n",
        "}\n",
        "\n",
        "config = Config(config_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HZbkyNDHup9r"
      },
      "outputs": [],
      "source": [
        "model = Transformer(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = batch['enc_inputs']\n",
        "dec_inputs = batch['dec_inputs'][:,1:]\n",
        "summary(model, input_data=[enc_inputs, dec_inputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Kua43sK3hp",
        "outputId": "24f836d0-0037-4419-e5ee-b82a772aff50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Transformer                                                       [64, 26, 32500]           --\n",
              "├─TransformerEncoder: 1-1                                         [64, 20, 256]             --\n",
              "│    └─Embedding: 2-1                                             [64, 20, 256]             8,320,000\n",
              "│    └─ModuleList: 2-2                                            --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1                          [64, 20, 256]             789,760\n",
              "│    │    └─TransformerEncoderLayer: 3-2                          [64, 20, 256]             789,760\n",
              "│    │    └─TransformerEncoderLayer: 3-3                          [64, 20, 256]             789,760\n",
              "├─TransformerDecoder: 1-2                                         [64, 26, 32500]           --\n",
              "│    └─Embedding: 2-3                                             [64, 26, 256]             8,320,000\n",
              "│    └─ModuleList: 2-4                                            --                        --\n",
              "│    │    └─TransformerDecoderLayer: 3-4                          [64, 26, 256]             1,053,440\n",
              "│    │    └─TransformerDecoderLayer: 3-5                          [64, 26, 256]             1,053,440\n",
              "│    │    └─TransformerDecoderLayer: 3-6                          [64, 26, 256]             1,053,440\n",
              "│    └─Linear: 2-5                                                [64, 26, 32500]           8,352,500\n",
              "===================================================================================================================\n",
              "Total params: 30,522,100\n",
              "Trainable params: 30,522,100\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.95\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 684.04\n",
              "Params size (MB): 122.09\n",
              "Estimated Total Size (MB): 806.15\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict = {\n",
        "    'vocab_size' : tokenizer.vocab_size,\n",
        "    'd_model' : 512,\n",
        "    'max_enc_len' : max_enc_len,\n",
        "    'max_dec_len' : max_dec_len,\n",
        "    'pad_id' : tokenizer.pad_token_id,\n",
        "    'bos_id' : tokenizer.bos_token_id,\n",
        "    'eos_id' : tokenizer.eos_token_id,\n",
        "    'use_decoder' : True,\n",
        "    'init_std' : 2e-2,\n",
        "    'norm_eps' : 1e-12, \n",
        "    'drop_out_raito' : 0.1,\n",
        "    'num_enc_layers' : 6,\n",
        "    'num_dec_layers' : 6,\n",
        "    'num_att_heads' : 4,\n",
        "    'feed_forward_dim' : 1024,\n",
        "}\n",
        "\n",
        "config = Config(config_dict)"
      ],
      "metadata": {
        "id": "_16zrZbdnjUR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(config)"
      ],
      "metadata": {
        "id": "17lzaRnynjW-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = batch['enc_inputs']\n",
        "dec_inputs = batch['dec_inputs'][:,1:]\n",
        "summary(model, input_data=[enc_inputs, dec_inputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqZq8ocxnjZm",
        "outputId": "a4de57e1-dd74-48db-9c14-0c0cb1f7826c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Transformer                                                       [64, 26, 32500]           --\n",
              "├─TransformerEncoder: 1-1                                         [64, 20, 512]             --\n",
              "│    └─Embedding: 2-1                                             [64, 20, 512]             16,640,000\n",
              "│    └─ModuleList: 2-2                                            --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-2                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-3                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-4                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-5                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-6                          [64, 20, 512]             2,102,784\n",
              "├─TransformerDecoder: 1-2                                         [64, 26, 32500]           --\n",
              "│    └─Embedding: 2-3                                             [64, 26, 512]             16,640,000\n",
              "│    └─ModuleList: 2                                              --                        --\n",
              "│    │    └─TransformerDecoderLayer: 3-7                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-8                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-9                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-10                         [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-11                         [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-12                         [64, 26, 512]             3,154,432\n",
              "│    └─Linear: 2-4                                                [64, 26, 32500]           16,672,500\n",
              "===================================================================================================================\n",
              "Total params: 81,495,796\n",
              "Trainable params: 81,495,796\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 5.22\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 1281.46\n",
              "Params size (MB): 325.98\n",
              "Estimated Total Size (MB): 1607.47\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RoT2h-IfmG-",
        "outputId": "01ac5358-7e55-45dc-9fea-a790335ef9e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=512, out_features=32500, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XT3sizK_lDR0"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BWcPVCw5v80A"
      },
      "outputs": [],
      "source": [
        "rouge = Rouge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4s8ySwPDvjqB"
      },
      "outputs": [],
      "source": [
        "def cal_rouge_n(y_pred, y_true):\n",
        "    y_pred = torch.argmax(y_pred, dim=-1)\n",
        "   \n",
        "    scores = []\n",
        "\n",
        "    for i in range(y_true.shape[0]):\n",
        "        score = 0\n",
        "        reference = tokenizer.decode(y_true[i])\n",
        "        hypothesis = tokenizer.decode(y_pred[i])\n",
        "        if ' </s>' in hypothesis:\n",
        "            \n",
        "            reference = reference.split(' </s>')[0].replace('.', ' +002E')\n",
        "            hypothesis = hypothesis.split(' </s>')[0].replace('.', ' +002E')\n",
        "\n",
        "            if len(hypothesis) != 0:\n",
        "              score = rouge.get_scores(hypothesis, reference)[0]['rouge-1']['f']\n",
        "        scores.append(round(score,4))\n",
        "\n",
        "    return sum(scores) / len(scores)\n",
        "\n",
        "    # reference = []\n",
        "    # hypothesis = []\n",
        "\n",
        "    # for i in range(y_true.shape[0]):\n",
        "    #     reference.append(tokenizer.decode(y_true[i]).split(' </s>')[0])\n",
        "    #     hypothesis.append(tokenizer.decode(y_pred[i]).split(' </s>')[0])\n",
        "\n",
        "    #     score = rouge.get_scores(hypothesis, reference)[0]['rouge-2']['f']\n",
        "    #     scores.append(round(score,4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O_QU0EYnOoz9"
      },
      "outputs": [],
      "source": [
        "def cal_lm_acc(y_pred, y_true, pad_id):\n",
        "    \"\"\"\n",
        "    acc 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # 정답 여부 확인\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).int()\n",
        "    matches = torch.eq(y_true, y_pred).int()\n",
        "    \n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = y_true.ne(pad_id).int()\n",
        "    matches *= mask\n",
        "    \n",
        "    # 정확도 계산\n",
        "    accuracy = torch.sum(matches) / torch.maximum(torch.sum(mask), torch.tensor(1, dtype=int))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LvJAlFrmlDU3"
      },
      "outputs": [],
      "source": [
        "def train_step(batch, epoch, training):\n",
        "    for batch_key in batch.keys():\n",
        "        batch[batch_key] = batch[batch_key].to(device)\n",
        "\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            logits = model(enc_inputs=batch['enc_inputs'],\n",
        "                           dec_inputs=batch['dec_inputs'][:,:-1])[0]\n",
        "            \n",
        "            CCE = nn.CrossEntropyLoss(ignore_index=config.pad_id)\n",
        "            loss = loss = CCE(logits.view(-1, config.vocab_size), batch['dec_inputs'][:,1:].contiguous().view(-1))\n",
        "            # lm_acc = cal_lm_acc(logits, batch['dec_inputs'][:,1:], config.pad_id)\n",
        "            rouge_1_f1 = cal_rouge_n(logits, batch['dec_inputs'][:,1:])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        return loss, rouge_1_f1, round(lr, 10)\n",
        "        # return loss, lm_acc, round(lr, 10)\n",
        "\n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(enc_inputs=batch['enc_inputs'],\n",
        "                           dec_inputs=batch['dec_inputs'][:,:-1])[0]\n",
        "\n",
        "            CCE = nn.CrossEntropyLoss(ignore_index=config.pad_id)\n",
        "            loss = loss = CCE(logits.view(-1, config.vocab_size), batch['dec_inputs'][:,1:].contiguous().view(-1))\n",
        "            # lm_acc = cal_lm_acc(logits, batch['dec_inputs'][:,1:], config.pad_id)\n",
        "            rouge_1_f1 = cal_rouge_n(logits, batch['dec_inputs'][:,1:])\n",
        "\n",
        "        return loss, rouge_1_f1\n",
        "        # return loss, lm_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class color:\n",
        "PURPLE = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "DARKCYAN = '\\033[36m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "RED = '\\033[91m'\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'"
      ],
      "metadata": {
        "id": "LBhQX6ttD1H5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv-2vjF24nTY",
        "outputId": "1a7dfbaf-b6fa-471a-a7ed-43c03a418858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:37<00:00,  4.60it/s,      Epoch=1,      \u001b[92mLoss=5.3271\u001b[0m,      \u001b[93mRouge_1_F1=0.2889\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.29it/s,        Epoch=1,  \u001b[92mVal Loss=3.9880\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.2934\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from     0 to 0.293 on epoch 1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:35<00:00,  4.97it/s,      Epoch=2,      \u001b[92mLoss=3.6532\u001b[0m,      \u001b[93mRouge_1_F1=0.2843\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:01<00:00,  9.60it/s,        Epoch=2,  \u001b[92mVal Loss=3.4263\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.2937\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.293 to 0.294 on epoch 2\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:43<00:00,  4.05it/s,      Epoch=3,      \u001b[92mLoss=3.1457\u001b[0m,      \u001b[93mRouge_1_F1=0.3013\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:01<00:00,  8.60it/s,        Epoch=3,  \u001b[92mVal Loss=3.0891\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3053\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.294 to 0.305 on epoch 3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:35<00:00,  4.91it/s,      Epoch=4,      \u001b[92mLoss=2.7259\u001b[0m,      \u001b[93mRouge_1_F1=0.3330\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.78it/s,        Epoch=4,  \u001b[92mVal Loss=2.9124\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3347\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.305 to 0.335 on epoch 4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:36<00:00,  4.75it/s,      Epoch=5,      \u001b[92mLoss=2.3085\u001b[0m,      \u001b[93mRouge_1_F1=0.3795\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:01<00:00,  8.48it/s,        Epoch=5,  \u001b[92mVal Loss=2.7362\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3492\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.335 to 0.349 on epoch 5\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:38<00:00,  4.50it/s,      Epoch=6,      \u001b[92mLoss=1.9031\u001b[0m,      \u001b[93mRouge_1_F1=0.4466\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.01it/s,        Epoch=6,  \u001b[92mVal Loss=2.6365\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3632\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.349 to 0.363 on epoch 6\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:34<00:00,  5.06it/s,      Epoch=7,      \u001b[92mLoss=1.5212\u001b[0m,      \u001b[93mRouge_1_F1=0.5317\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.01it/s,        Epoch=7,  \u001b[92mVal Loss=2.5240\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3864\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.363 to 0.386 on epoch 7\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:34<00:00,  5.01it/s,      Epoch=8,      \u001b[92mLoss=1.1784\u001b[0m,      \u001b[93mRouge_1_F1=0.6236\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.00it/s,        Epoch=8,  \u001b[92mVal Loss=2.5095\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3928\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.386 to 0.393 on epoch 8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:34<00:00,  5.02it/s,      Epoch=9,      \u001b[92mLoss=0.8866\u001b[0m,      \u001b[93mRouge_1_F1=0.7194\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:01<00:00,  9.42it/s,        Epoch=9,  \u001b[92mVal Loss=2.4431\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4012\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.393 to 0.401 on epoch 9\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:34<00:00,  5.00it/s,      Epoch=10,      \u001b[92mLoss=0.6487\u001b[0m,      \u001b[93mRouge_1_F1=0.7971\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.15it/s,        Epoch=10,  \u001b[92mVal Loss=2.3773\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4522\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.401 to 0.452 on epoch 10\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:33<00:00,  5.12it/s,      Epoch=11,      \u001b[92mLoss=0.4623\u001b[0m,      \u001b[93mRouge_1_F1=0.8630\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.10it/s,        Epoch=11,  \u001b[92mVal Loss=2.4682\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4325\u001b[0m]\n",
            "100%|██████████| 174/174 [00:34<00:00,  4.99it/s,      Epoch=12,      \u001b[92mLoss=0.3245\u001b[0m,      \u001b[93mRouge_1_F1=0.9157\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.49it/s,        Epoch=12,  \u001b[92mVal Loss=2.4451\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4459\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.96it/s,      Epoch=13,      \u001b[92mLoss=0.2205\u001b[0m,      \u001b[93mRouge_1_F1=0.9514\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.74it/s,        Epoch=13,  \u001b[92mVal Loss=2.4810\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4486\u001b[0m]\n",
            "100%|██████████| 174/174 [00:34<00:00,  5.01it/s,      Epoch=14,      \u001b[92mLoss=0.1485\u001b[0m,      \u001b[93mRouge_1_F1=0.9749\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.29it/s,        Epoch=14,  \u001b[92mVal Loss=2.3960\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4694\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.452 to 0.469 on epoch 14\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:35<00:00,  4.95it/s,      Epoch=15,      \u001b[92mLoss=0.1033\u001b[0m,      \u001b[93mRouge_1_F1=0.9850\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.59it/s,        Epoch=15,  \u001b[92mVal Loss=2.3730\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4893\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.469 to 0.489 on epoch 15\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:35<00:00,  4.96it/s,      Epoch=16,      \u001b[92mLoss=0.0740\u001b[0m,      \u001b[93mRouge_1_F1=0.9884\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.22it/s,        Epoch=16,  \u001b[92mVal Loss=2.5645\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4591\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.95it/s,      Epoch=17,      \u001b[92mLoss=0.0539\u001b[0m,      \u001b[93mRouge_1_F1=0.9911\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 11.03it/s,        Epoch=17,  \u001b[92mVal Loss=2.6483\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4570\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.91it/s,      Epoch=18,      \u001b[92mLoss=0.0447\u001b[0m,      \u001b[93mRouge_1_F1=0.9920\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.38it/s,        Epoch=18,  \u001b[92mVal Loss=2.5947\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4596\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.97it/s,      Epoch=19,      \u001b[92mLoss=0.0440\u001b[0m,      \u001b[93mRouge_1_F1=0.9909\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:01<00:00,  9.72it/s,        Epoch=19,  \u001b[92mVal Loss=2.5647\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4720\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.94it/s,      Epoch=20,      \u001b[92mLoss=0.0711\u001b[0m,      \u001b[93mRouge_1_F1=0.9797\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.88it/s,        Epoch=20,  \u001b[92mVal Loss=2.7834\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4472\u001b[0m]\n",
            "100%|██████████| 174/174 [00:34<00:00,  4.97it/s,      Epoch=21,      \u001b[92mLoss=0.0918\u001b[0m,      \u001b[93mRouge_1_F1=0.9678\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.62it/s,        Epoch=21,  \u001b[92mVal Loss=2.5247\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4599\u001b[0m]\n",
            "100%|██████████| 174/174 [00:35<00:00,  4.90it/s,      Epoch=22,      \u001b[92mLoss=0.0593\u001b[0m,      \u001b[93mRouge_1_F1=0.9818\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 10.60it/s,        Epoch=22,  \u001b[92mVal Loss=2.6197\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4514\u001b[0m]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12min 13s, sys: 35.1 s, total: 12min 48s\n",
            "Wall time: 13min 42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# train\n",
        "\n",
        "loss_plot, val_loss_plot = [], []\n",
        "lrs = []\n",
        "\n",
        "check_list = []\n",
        "\n",
        "best_val_rouge_1_f1 = 0\n",
        "best_val_loss = 100\n",
        "\n",
        "best_epoch = 0\n",
        "patience = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_rouge_1_f1, total_val_rouge_1_f1 = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader), total=train_dataloader.__len__())\n",
        "    training = True\n",
        "    for batch_idx, batch in tqdm_dataset:\n",
        "        batch_loss, batch_rouge_1_f1, lr = train_step(batch, epoch, training)\n",
        "        total_loss += batch_loss\n",
        "        total_rouge_1_f1 += batch_rouge_1_f1\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            '%+10s' % 'Epoch': epoch + 1,\n",
        "            '%10s' % GREEN + 'Loss' : '{:.4f}'.format(total_loss/(batch_idx+1)) + END,\n",
        "            '%10s' % YELLOW + 'Rouge_1_F1' : '{:.4f}'.format(total_rouge_1_f1/(batch_idx+1)) + END,\n",
        "            '%5s' % 'LR' : lr,\n",
        "        })\n",
        "            \n",
        "    loss_plot.append(total_loss/(batch_idx+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(valid_dataloader), total=valid_dataloader.__len__())\n",
        "    training = False\n",
        "    for batch_idx, batch in tqdm_dataset:\n",
        "        batch_loss, batch_rouge_1_f1 = train_step(batch, epoch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_rouge_1_f1 += batch_rouge_1_f1\n",
        "\n",
        "        tqdm_dataset.set_postfix({\n",
        "            '%+12s' % 'Epoch': epoch + 1,\n",
        "            '%6s' % GREEN + 'Val Loss' : '{:.4f}'.format(total_val_loss/(batch_idx+1)) + END,\n",
        "            '%6s' % YELLOW + 'Val Rouge_1_F1' : '{:.4f}'.format(total_val_rouge_1_f1/(batch_idx+1)) + END,\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch_idx+1)) \n",
        "\n",
        "    cur_val_loss = round(float((total_val_loss/(batch_idx+1)).detach().cpu()), 3)\n",
        "    cur_val_rouge_1_f1 = round(float((total_val_rouge_1_f1/(batch_idx+1))), 3)\n",
        "\n",
        "    # cur_val_loss = round(total_val_loss/(batch_idx+1), 4)\n",
        "    # cur_val_rouge_1_f1 = round(total_val_rouge_1_f1/(batch_idx+1), 4)\n",
        "\n",
        "    # if cur_val_loss < best_val_loss:\n",
        "    if cur_val_rouge_1_f1 > best_val_rouge_1_f1:\n",
        "        print(YELLOW + 'Best_Val_Rouge_1_F1 is updated from {:>5} to {:>5} on epoch {}'.format(best_val_rouge_1_f1, cur_val_rouge_1_f1, epoch+1) + END)\n",
        "        best_val_rouge_1_f1 = cur_val_rouge_1_f1\n",
        "        best_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), './'+save_name+'.ckpt')\n",
        "        if best_epoch > 15:\n",
        "            torch.save(model.state_dict(), './'+save_name+'_loss_{}_val_rouge_1_f1_{}.ckpt'.format(cur_val_loss, cur_val_rouge_1_f1))\n",
        "            patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "    \n",
        "    lrs.append(lr)\n",
        "    \n",
        "    if patience == early_stopping_patience:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9ZwKB-qmLNZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc4bb2b-7d9e-4bc0-bbdd-c904360d8fca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/Transformer/PyTorch/tft_model.ckpt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "lCOajkIDgCJs"
      },
      "outputs": [],
      "source": [
        "def inference(text, enc_max_len):\n",
        "    enc_inputs = mk_token_inputs(text, enc_max_len).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(enc_inputs)[0]\n",
        "    \n",
        "    outputs = torch.argmax(logits, dim=-1).to('cpu')[0]\n",
        "    outputs = tokenizer.decode(outputs).split(' </s>')[0]\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DmJUg1slNpFO"
      },
      "outputs": [],
      "source": [
        "# text = '오늘 진짜 좋은 일 있었어!'\n",
        "text = '아 슬슬 피곤하네'\n",
        "# text = '잘까? 어떡하지?'\n",
        "# text = '학습 잘 된 걸까?'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference(text, config.max_enc_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GuNG-xRgkmXQ",
        "outputId": "724f20d0-e62d-499e-d1c4-f0fba79449d5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사랑하는 시간만큼 또 다시 들으세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DHkDG0aUXtGP"
      },
      "outputs": [],
      "source": [
        "def inference(text, max_enc_len):\n",
        "    # enc_token 생성: <string tokens>, [PAD] tokens\n",
        "    enc_token = tokenizer.encode(text, max_length=max_enc_len, padding='max_length')\n",
        "    # dec_token 생성: [BOS], [PAD] tokens\n",
        "    dec_token = [config.bos_id]\n",
        "    dec_token += [0] * (config.max_dec_len - len(dec_token))\n",
        "    dec_token = dec_token[:config.max_dec_len]\n",
        "\n",
        "    response = []\n",
        "    for i in range(config.max_dec_len - 1):\n",
        "        output = model(torch.tensor([enc_token]).to(device), torch.tensor([dec_token]).to(device))[0].detach().cpu().numpy()\n",
        "        word_id = int(np.argmax(output, axis=2)[0][i])\n",
        "\n",
        "        # [EOS] 토큰이 생성되면 종료\n",
        "        if word_id == config.eos_id:\n",
        "            break\n",
        "        # 예측된 token을 응답에 저장\n",
        "        response.append(word_id)\n",
        "        # 예측된 token을 decoder의 다음 입력으로 저장\n",
        "        dec_token[i + 1] = word_id\n",
        "    \n",
        "    return tokenizer.decode(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference(text, config.max_enc_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "90Cpz33DoExR",
        "outputId": "cef9de01-3855-4336-ee59-2937298dec31"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사랑하는 시간만큼 또 다시 들으세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('종료를 원하실 시에는 exit를 입력해주세요.')\n",
        "while True:\n",
        "    print(\"input > \", end=\"\")\n",
        "    string = str(input())\n",
        "    if string == 'exit':\n",
        "        break\n",
        "    print(f\"output > {inference(string, config.max_enc_len)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqUXzZEIpjaa",
        "outputId": "79cbebb7-a075-401c-ee05-4502953af5ec"
      },
      "execution_count": 59,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종료를 원하실 시에는 exit를 입력해주세요.\n",
            "input > 안녕하세요\n",
            "output > 안녕하세요.\n",
            "input > 챗봇이에요?\n",
            "output > 저는 사람으로 태어나고 싶어요.\n",
            "input > exit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
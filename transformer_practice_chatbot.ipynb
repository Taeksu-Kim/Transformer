{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY9gIZoPREnL",
        "outputId": "cd04be5e-9de5-4db8-8b3f-e283eea68c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.7\n",
            "  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 15.1 MB/s \n",
            "\u001b[?25hCollecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (4.64.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (4.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7) (2022.6.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=042008131c0109c6a0fec0c973b7cc052caeb72e7bcc89a4e017cd12b7ea82ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, torchinfo, rouge\n",
            "Successfully installed huggingface-hub-0.0.8 rouge-1.0.1 sacremoses-0.0.53 tokenizers-0.10.3 torchinfo-1.7.0 transformers-4.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.7 torchinfo rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYucaGAGRmJX",
        "outputId": "74914a5e-bf2e-4cd1-f2a7-6197f65dedb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Transformer'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 66 (delta 26), reused 38 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Taeksu-Kim/Transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHZ0wWoTRmLv",
        "outputId": "5b05c746-78bf-41f4-f5ee-bbf652a62402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Transformer/PyTorch\n"
          ]
        }
      ],
      "source": [
        "cd Transformer/PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUltP3SVSDN2",
        "outputId": "4f81fe74-794a-42bf-ab49-ed7f214dea6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chatbot_data'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 57 (delta 21), reused 6 (delta 3), pack-reused 18\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "soWE65AlSDP9"
      },
      "outputs": [],
      "source": [
        "# common\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchinfo import summary\n",
        "from rouge import Rouge\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# custom\n",
        "from transformer import Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kOxo_8pmc0tI"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed = 42\n",
        "\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OyV4zC-teD-Y"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 300\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-2\n",
        "batch_size = 64\n",
        "\n",
        "gradient_scaler = True\n",
        "# use_lr_scheduler = False\n",
        "\n",
        "early_stopping_patience = 10\n",
        "\n",
        "save_name = 'tft_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j8H6qx8HZW4Y"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./Chatbot_data/ChatbotData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vcy_7abBaWGX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "564fb46fe2d043f298fc676037ced098",
            "79257321d69b4eff91ed3ad59ba84fe3",
            "99f129d10c214a0bbdbd44cff92af75f",
            "eccd5c6c0fa040e9b032a895f3e8465f",
            "0bcbd8b57b9c41dc93fbc43b0c032f9f",
            "6af8b817607148b29b82ce7927fd846b",
            "5bc1d950894448faaa1a8d9c7e58882f",
            "c5f0ae9dab634e85b3017632305d55a9",
            "46565c9c6fc74d5bbdc1453950e5647d",
            "54797ebddf484d2a81e7695ae88e41dd",
            "72e45ac7c7d4401bbed6e9b9f6b51a55",
            "b65a8d0049834c40b59cf778afaf9c07",
            "b2190d102f7a4f45abb5fd16ca570580",
            "9102c92bd89b468b89cc319335d7ac3e",
            "68398a1731fd4a5daf5dc2faaa40fc81",
            "45c6aa0c27d644f486257d109774adcc",
            "246ba84c79d74d17b21f49f1f33da225",
            "bc0bb90f3dbe4da8bbc0807141a92249",
            "7b30a8717437444988588ffba3ce294f",
            "f8c9d431c69e463083d242b1ea68a532",
            "eee958f453ec4d74b1094c699ebef3b5",
            "3015244bc92f47d981e835c55df2a406",
            "9e5973a7e155427e8fea6f6538b82f77",
            "d6c17f2760d3408cae36b86163774dd1",
            "a81bec6d897d4777a6994fe191216326",
            "78e2523dc74d42e992f2d940b17fb54c",
            "f9c171ec61f84d1b9dd6229631917e87",
            "8590be22b0d54104824dc9d24286404a",
            "7eb23dd0171a48b892fce36f5e6c0dec",
            "d0c3eae28e0847a48dd253319988f5bb",
            "272009d037e14d72987e6e5268e4bebd",
            "ecd62daa2c6747b194f38e8e5a6b5169",
            "bee3af92229d4ce19113cd7f9363d453",
            "46272c31202747c981150a82ea3a9f15",
            "57dd16b853ce4628b1c79d8054fd9531",
            "33d4ca9b8d7740f18e37cb7359d7992f",
            "79e9db05873f453db7bd0dc072aa1587",
            "846adc4447c6430e8f2734bf842c3332",
            "9dbe00ee63dd47afb06480cdd1d88fc4",
            "c1df5292fe8a477991f2c7081294b467",
            "dd4d25ce6d394311a2d7524cc3b24bd9",
            "b934495e04cc4956b7899de8670955cd",
            "fd47ae19f9b24d05b154cd274e67e62f",
            "49f1118a9b7b45f7a07b5619e025833b",
            "573dfdf1f7044d13aa2746ea5881b9f4",
            "3b50e14a25e0428cb8a1e37c7014d13c",
            "822383b1670f4b21b0d2ba4319a67421",
            "2793fd715b804cf993723e1a13adc75b",
            "593c6ca3faba4b8a8b798df2bfdfbfbe",
            "02258a4ba96c4c57ae6bcb8c3a0435cc",
            "b3ca82a0ec4b484399fa2c7a785baa11",
            "8b8307a4bffc4d998501c85d7bbde439",
            "07476a9d9b884784850fe6b2d72ad3a0",
            "839df2a601d14b1aac40f99d46582e69",
            "9486cfb6779341a19f8f00f852e986b2"
          ]
        },
        "outputId": "88003d8c-891f-4e55-bb34-a438de585d45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/870 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "564fb46fe2d043f298fc676037ced098"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/241k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b65a8d0049834c40b59cf778afaf9c07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/492k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e5973a7e155427e8fea6f6538b82f77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/169 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46272c31202747c981150a82ea3a9f15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "573dfdf1f7044d13aa2746ea5881b9f4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_path = \"monologg/kobigbird-bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hBob5L-SZW7Q"
      },
      "outputs": [],
      "source": [
        "def cal_token_len(text, tokenizer):\n",
        "  return len(tokenizer.encode(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsFzl3chZW93",
        "outputId": "6c2d263c-8b72-48c3-9517-c56e409f7c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11823/11823 [00:03<00:00, 3319.13it/s]\n"
          ]
        }
      ],
      "source": [
        "df['enc_token_len'] = [ cal_token_len(df.iloc[i]['Q'], tokenizer) for i in tqdm(range(df.shape[0])) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx6dRe2uaFj-",
        "outputId": "630ab84d-887d-4781-beec-4dffa47bafa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11823/11823 [00:02<00:00, 4155.29it/s]\n"
          ]
        }
      ],
      "source": [
        "df['dec_token_len'] = [ cal_token_len(df.iloc[i]['A'], tokenizer) for i in tqdm(range(df.shape[0])) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RdbgeiIOaABF",
        "outputId": "88961a81-d514-44d3-84f7-457d042b3569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label  enc_token_len  dec_token_len\n",
              "0           12시 땡!   하루가 또 가네요.      0              6              8\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0              8              6\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0             11              8\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0             12              8\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0              6              9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-863b4043-765b-4e10-a6df-a12febe65c05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "      <th>enc_token_len</th>\n",
              "      <th>dec_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-863b4043-765b-4e10-a6df-a12febe65c05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-863b4043-765b-4e10-a6df-a12febe65c05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-863b4043-765b-4e10-a6df-a12febe65c05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaGKGsU4ZXAo",
        "outputId": "9f48961c-b902-4506-e17c-163db818e966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% length : 16.0\n",
            "98% length : 19.0\n",
            "99% length : 20.0\n",
            "100% length : 30.0\n"
          ]
        }
      ],
      "source": [
        "tar_per_list = [95,98,99,100]\n",
        "tar_col = df['enc_token_len']\n",
        "\n",
        "for i in tar_per_list:\n",
        "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Jz98uJmWbtMQ"
      },
      "outputs": [],
      "source": [
        "max_enc_len = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hcjVQjZXDP",
        "outputId": "4463d686-5e5a-4e3b-e860-06d311556a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% length : 18.0\n",
            "98% length : 20.0\n",
            "99% length : 23.0\n",
            "100% length : 42.0\n"
          ]
        }
      ],
      "source": [
        "tar_col = df['dec_token_len']\n",
        "\n",
        "for i in tar_per_list:\n",
        "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uAh_OP14ZXF5"
      },
      "outputs": [],
      "source": [
        "max_dec_len = 26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "79qHoTj_b45G"
      },
      "outputs": [],
      "source": [
        "df = df[(df['enc_token_len']<=max_enc_len)&(df['dec_token_len']<=max_dec_len)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iCEH0pGxb47l",
        "outputId": "2c7bc3e2-c9ac-4fad-83f4-92e3417432bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label  enc_token_len  dec_token_len\n",
              "0           12시 땡!   하루가 또 가네요.      0              6              8\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0              8              6\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0             11              8\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0             12              8\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0              6              9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eccbc9b5-0ec1-45c2-90ec-da3011ed43c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "      <th>enc_token_len</th>\n",
              "      <th>dec_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eccbc9b5-0ec1-45c2-90ec-da3011ed43c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eccbc9b5-0ec1-45c2-90ec-da3011ed43c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eccbc9b5-0ec1-45c2-90ec-da3011ed43c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C-oykEIycXwS"
      },
      "outputs": [],
      "source": [
        "train, valid =  train_test_split(df, test_size=0.05, random_state=seed, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9TnBv06gTrHE"
      },
      "outputs": [],
      "source": [
        "def mk_token_inputs(text, max_seq_len, mode='encoder'):\n",
        "    input_ids = tokenizer.encode(text,max_length=max_seq_len, padding='max_length')\n",
        "    \n",
        "    if mode == 'decoder':\n",
        "      cls_idx = input_ids.index(tokenizer.cls_token_id)\n",
        "      sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "      input_ids[cls_idx] = tokenizer.bos_token_id\n",
        "      input_ids[sep_idx] = tokenizer.eos_token_id\n",
        "\n",
        "    return torch.tensor(input_ids, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EHnr6x_4bk0W"
      },
      "outputs": [],
      "source": [
        "class chatbot_dataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, enc_max_len, dec_max_len):\n",
        "    self.df = df\n",
        "    self.enc_max_len = enc_max_len\n",
        "    self.dec_max_len = dec_max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return {'enc_inputs' : mk_token_inputs(self.df['Q'].iloc[index], self.enc_max_len),\n",
        "            'dec_inputs' : mk_token_inputs(self.df['A'].iloc[index], self.dec_max_len, mode='decoder'),\n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Uee1UbQRbthI"
      },
      "outputs": [],
      "source": [
        "train_dataset = chatbot_dataset(train, max_enc_len, max_dec_len+1)\n",
        "valid_dataset = chatbot_dataset(valid, max_enc_len, max_dec_len+1)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "woHDPphObk21"
      },
      "outputs": [],
      "source": [
        "for i, batch in enumerate(train_dataloader):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "00eqSz3Bbkpm"
      },
      "outputs": [],
      "source": [
        "# Config Class\n",
        "# dict class를 json으로 바꿔서 confg.arg 와 같이 사용할 수 있게 만드는 class\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dWOa15pObksU"
      },
      "outputs": [],
      "source": [
        "config_dict = {\n",
        "    'vocab_size' : tokenizer.vocab_size,\n",
        "    'd_model' : 256,\n",
        "    'max_enc_len' : max_enc_len,\n",
        "    'max_dec_len' : max_dec_len,\n",
        "    'pad_id' : tokenizer.pad_token_id,\n",
        "    'bos_id' : tokenizer.bos_token_id,\n",
        "    'eos_id' : tokenizer.eos_token_id,\n",
        "    'use_decoder' : True,\n",
        "    'init_std' : 2e-2,\n",
        "    'norm_eps' : 1e-12, \n",
        "    'drop_out_raito' : 0.1,\n",
        "    'num_enc_layers' : 3,\n",
        "    'num_dec_layers' : 3,\n",
        "    'num_att_heads' : 4,\n",
        "    'feed_forward_dim' : 1024,\n",
        "}\n",
        "\n",
        "config = Config(config_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HZbkyNDHup9r"
      },
      "outputs": [],
      "source": [
        "model = Transformer(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = batch['enc_inputs']\n",
        "dec_inputs = batch['dec_inputs'][:,1:]\n",
        "summary(model, input_data=[enc_inputs, dec_inputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Kua43sK3hp",
        "outputId": "06ee1987-e9a2-4ec7-9e2c-8ab8d2c7bba5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Transformer                                                       [64, 26, 32500]           --\n",
              "├─TransformerEncoder: 1-1                                         [64, 20, 256]             --\n",
              "│    └─Embedding: 2-1                                             [64, 20, 256]             8,320,000\n",
              "│    └─ModuleList: 2-2                                            --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1                          [64, 20, 256]             789,760\n",
              "│    │    └─TransformerEncoderLayer: 3-2                          [64, 20, 256]             789,760\n",
              "│    │    └─TransformerEncoderLayer: 3-3                          [64, 20, 256]             789,760\n",
              "├─TransformerDecoder: 1-2                                         [64, 26, 32500]           --\n",
              "│    └─Embedding: 2-3                                             [64, 26, 256]             8,320,000\n",
              "│    └─ModuleList: 2-4                                            --                        --\n",
              "│    │    └─TransformerDecoderLayer: 3-4                          [64, 26, 256]             1,053,440\n",
              "│    │    └─TransformerDecoderLayer: 3-5                          [64, 26, 256]             1,053,440\n",
              "│    │    └─TransformerDecoderLayer: 3-6                          [64, 26, 256]             1,053,440\n",
              "│    └─Linear: 2-5                                                [64, 26, 32500]           8,352,500\n",
              "===================================================================================================================\n",
              "Total params: 30,522,100\n",
              "Trainable params: 30,522,100\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.95\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 684.04\n",
              "Params size (MB): 122.09\n",
              "Estimated Total Size (MB): 806.15\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict = {\n",
        "    'vocab_size' : tokenizer.vocab_size,\n",
        "    'd_model' : 512,\n",
        "    'max_enc_len' : max_enc_len,\n",
        "    'max_dec_len' : max_dec_len,\n",
        "    'pad_id' : tokenizer.pad_token_id,\n",
        "    'bos_id' : tokenizer.bos_token_id,\n",
        "    'eos_id' : tokenizer.eos_token_id,\n",
        "    'use_decoder' : True,\n",
        "    'init_std' : 2e-2,\n",
        "    'norm_eps' : 1e-12, \n",
        "    'drop_out_raito' : 0.1,\n",
        "    'num_enc_layers' : 6,\n",
        "    'num_dec_layers' : 6,\n",
        "    'num_att_heads' : 4,\n",
        "    'feed_forward_dim' : 1024,\n",
        "}\n",
        "\n",
        "config = Config(config_dict)"
      ],
      "metadata": {
        "id": "_16zrZbdnjUR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(config)"
      ],
      "metadata": {
        "id": "17lzaRnynjW-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = batch['enc_inputs']\n",
        "dec_inputs = batch['dec_inputs'][:,1:]\n",
        "summary(model, input_data=[enc_inputs, dec_inputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqZq8ocxnjZm",
        "outputId": "85dd311a-8d78-42a3-9a16-b73c35e1839a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Transformer                                                       [64, 26, 32500]           --\n",
              "├─TransformerEncoder: 1-1                                         [64, 20, 512]             --\n",
              "│    └─Embedding: 2-1                                             [64, 20, 512]             16,640,000\n",
              "│    └─ModuleList: 2-2                                            --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-2                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-3                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-4                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-5                          [64, 20, 512]             2,102,784\n",
              "│    │    └─TransformerEncoderLayer: 3-6                          [64, 20, 512]             2,102,784\n",
              "├─TransformerDecoder: 1-2                                         [64, 26, 32500]           --\n",
              "│    └─Embedding: 2-3                                             [64, 26, 512]             16,640,000\n",
              "│    └─ModuleList: 2                                              --                        --\n",
              "│    │    └─TransformerDecoderLayer: 3-7                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-8                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-9                          [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-10                         [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-11                         [64, 26, 512]             3,154,432\n",
              "│    │    └─TransformerDecoderLayer: 3-12                         [64, 26, 512]             3,154,432\n",
              "│    └─Linear: 2-4                                                [64, 26, 32500]           16,672,500\n",
              "===================================================================================================================\n",
              "Total params: 81,495,796\n",
              "Trainable params: 81,495,796\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 5.22\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 1281.46\n",
              "Params size (MB): 325.98\n",
              "Estimated Total Size (MB): 1607.47\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RoT2h-IfmG-",
        "outputId": "d1eebebe-67cc-442b-f887-ae361473b7e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=512, out_features=32500, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XT3sizK_lDR0"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BWcPVCw5v80A"
      },
      "outputs": [],
      "source": [
        "rouge = Rouge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4s8ySwPDvjqB"
      },
      "outputs": [],
      "source": [
        "def cal_rouge_n(y_pred, y_true):\n",
        "    y_pred = torch.argmax(y_pred, dim=-1)\n",
        "   \n",
        "    scores = []\n",
        "\n",
        "    for i in range(y_true.shape[0]):\n",
        "        score = 0\n",
        "        reference = tokenizer.decode(y_true[i])\n",
        "        hypothesis = tokenizer.decode(y_pred[i])\n",
        "        if ' </s>' in hypothesis:\n",
        "            \n",
        "            reference = reference.split(' </s>')[0].replace('.', ' +002E')\n",
        "            hypothesis = hypothesis.split(' </s>')[0].replace('.', ' +002E')\n",
        "\n",
        "            if len(hypothesis) != 0:\n",
        "              score = rouge.get_scores(hypothesis, reference)[0]['rouge-1']['f']\n",
        "        scores.append(round(score,4))\n",
        "\n",
        "    return sum(scores) / len(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O_QU0EYnOoz9"
      },
      "outputs": [],
      "source": [
        "def cal_lm_acc(y_pred, y_true, pad_id):\n",
        "    \"\"\"\n",
        "    acc 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # 정답 여부 확인\n",
        "    y_pred = torch.argmax(y_pred, dim=-1).int()\n",
        "    matches = torch.eq(y_true, y_pred).int()\n",
        "    \n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = y_true.ne(pad_id).int()\n",
        "    matches *= mask\n",
        "    \n",
        "    # 정확도 계산\n",
        "    accuracy = torch.sum(matches) / torch.maximum(torch.sum(mask), torch.tensor(1, dtype=int))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LvJAlFrmlDU3"
      },
      "outputs": [],
      "source": [
        "def train_step(batch, epoch, training):\n",
        "    for batch_key in batch.keys():\n",
        "        batch[batch_key] = batch[batch_key].to(device)\n",
        "\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            logits = model(enc_inputs=batch['enc_inputs'],\n",
        "                           dec_inputs=batch['dec_inputs'][:,:-1])[0]\n",
        "            \n",
        "            CCE = nn.CrossEntropyLoss(ignore_index=config.pad_id)\n",
        "            loss = loss = CCE(logits.view(-1, config.vocab_size), batch['dec_inputs'][:,1:].contiguous().view(-1))\n",
        "            # lm_acc = cal_lm_acc(logits, batch['dec_inputs'][:,1:], config.pad_id)\n",
        "            rouge_1_f1 = cal_rouge_n(logits, batch['dec_inputs'][:,1:])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        return loss, rouge_1_f1, round(lr, 10)\n",
        "        # return loss, lm_acc, round(lr, 10)\n",
        "\n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(enc_inputs=batch['enc_inputs'],\n",
        "                           dec_inputs=batch['dec_inputs'][:,:-1])[0]\n",
        "\n",
        "            CCE = nn.CrossEntropyLoss(ignore_index=config.pad_id)\n",
        "            loss = loss = CCE(logits.view(-1, config.vocab_size), batch['dec_inputs'][:,1:].contiguous().view(-1))\n",
        "            # lm_acc = cal_lm_acc(logits, batch['dec_inputs'][:,1:], config.pad_id)\n",
        "            rouge_1_f1 = cal_rouge_n(logits, batch['dec_inputs'][:,1:])\n",
        "\n",
        "        return loss, rouge_1_f1\n",
        "        # return loss, lm_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class color:\n",
        "PURPLE = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "DARKCYAN = '\\033[36m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "RED = '\\033[91m'\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'"
      ],
      "metadata": {
        "id": "LBhQX6ttD1H5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv-2vjF24nTY",
        "outputId": "29a8568d-dec5-4b7f-f48d-b1680cfb5e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:27<00:00,  6.32it/s,      Epoch=1,      \u001b[92mLoss=5.3277\u001b[0m,      \u001b[93mRouge_1_F1=0.2886\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.91it/s,        Epoch=1,  \u001b[92mVal Loss=3.9877\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.2986\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from     0 to 0.299 on epoch 1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.78it/s,      Epoch=2,      \u001b[92mLoss=3.6535\u001b[0m,      \u001b[93mRouge_1_F1=0.2850\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.37it/s,        Epoch=2,  \u001b[92mVal Loss=3.4309\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.2924\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.78it/s,      Epoch=3,      \u001b[92mLoss=3.1448\u001b[0m,      \u001b[93mRouge_1_F1=0.3019\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.38it/s,        Epoch=3,  \u001b[92mVal Loss=3.0863\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3049\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.299 to 0.305 on epoch 3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.74it/s,      Epoch=4,      \u001b[92mLoss=2.7256\u001b[0m,      \u001b[93mRouge_1_F1=0.3329\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.22it/s,        Epoch=4,  \u001b[92mVal Loss=2.9097\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3348\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.305 to 0.335 on epoch 4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.77it/s,      Epoch=5,      \u001b[92mLoss=2.3074\u001b[0m,      \u001b[93mRouge_1_F1=0.3805\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.29it/s,        Epoch=5,  \u001b[92mVal Loss=2.7410\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3491\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.335 to 0.349 on epoch 5\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.77it/s,      Epoch=6,      \u001b[92mLoss=1.9024\u001b[0m,      \u001b[93mRouge_1_F1=0.4469\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.34it/s,        Epoch=6,  \u001b[92mVal Loss=2.6504\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3648\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.349 to 0.365 on epoch 6\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.75it/s,      Epoch=7,      \u001b[92mLoss=1.5208\u001b[0m,      \u001b[93mRouge_1_F1=0.5299\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.06it/s,        Epoch=7,  \u001b[92mVal Loss=2.5323\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3903\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.365 to  0.39 on epoch 7\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.70it/s,      Epoch=8,      \u001b[92mLoss=1.1783\u001b[0m,      \u001b[93mRouge_1_F1=0.6255\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.15it/s,        Epoch=8,  \u001b[92mVal Loss=2.5209\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.3940\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from  0.39 to 0.394 on epoch 8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.74it/s,      Epoch=9,      \u001b[92mLoss=0.8864\u001b[0m,      \u001b[93mRouge_1_F1=0.7174\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.15it/s,        Epoch=9,  \u001b[92mVal Loss=2.4424\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4024\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.394 to 0.402 on epoch 9\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.73it/s,      Epoch=10,      \u001b[92mLoss=0.6472\u001b[0m,      \u001b[93mRouge_1_F1=0.7989\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.44it/s,        Epoch=10,  \u001b[92mVal Loss=2.3564\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4462\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.402 to 0.446 on epoch 10\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.75it/s,      Epoch=11,      \u001b[92mLoss=0.4604\u001b[0m,      \u001b[93mRouge_1_F1=0.8654\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.02it/s,        Epoch=11,  \u001b[92mVal Loss=2.4739\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4330\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.72it/s,      Epoch=12,      \u001b[92mLoss=0.3228\u001b[0m,      \u001b[93mRouge_1_F1=0.9153\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.93it/s,        Epoch=12,  \u001b[92mVal Loss=2.4295\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4474\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.446 to 0.447 on epoch 12\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.75it/s,      Epoch=13,      \u001b[92mLoss=0.2186\u001b[0m,      \u001b[93mRouge_1_F1=0.9528\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.01it/s,        Epoch=13,  \u001b[92mVal Loss=2.4883\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4499\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.447 to  0.45 on epoch 13\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.70it/s,      Epoch=14,      \u001b[92mLoss=0.1488\u001b[0m,      \u001b[93mRouge_1_F1=0.9747\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.98it/s,        Epoch=14,  \u001b[92mVal Loss=2.3523\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4691\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from  0.45 to 0.469 on epoch 14\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.71it/s,      Epoch=15,      \u001b[92mLoss=0.1046\u001b[0m,      \u001b[93mRouge_1_F1=0.9839\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.99it/s,        Epoch=15,  \u001b[92mVal Loss=2.3416\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4879\u001b[0m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mBest_Val_Rouge_1_F1 is updated from 0.469 to 0.488 on epoch 15\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:22<00:00,  7.75it/s,      Epoch=16,      \u001b[92mLoss=0.0770\u001b[0m,      \u001b[93mRouge_1_F1=0.9880\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.88it/s,        Epoch=16,  \u001b[92mVal Loss=2.5229\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4630\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.69it/s,      Epoch=17,      \u001b[92mLoss=0.0575\u001b[0m,      \u001b[93mRouge_1_F1=0.9902\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.02it/s,        Epoch=17,  \u001b[92mVal Loss=2.6043\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4639\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.71it/s,      Epoch=18,      \u001b[92mLoss=0.0462\u001b[0m,      \u001b[93mRouge_1_F1=0.9908\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.97it/s,        Epoch=18,  \u001b[92mVal Loss=2.5596\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4633\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.71it/s,      Epoch=19,      \u001b[92mLoss=0.0413\u001b[0m,      \u001b[93mRouge_1_F1=0.9914\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 14.01it/s,        Epoch=19,  \u001b[92mVal Loss=2.5106\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4738\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.68it/s,      Epoch=20,      \u001b[92mLoss=0.0604\u001b[0m,      \u001b[93mRouge_1_F1=0.9823\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.53it/s,        Epoch=20,  \u001b[92mVal Loss=2.7851\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4546\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.68it/s,      Epoch=21,      \u001b[92mLoss=0.0833\u001b[0m,      \u001b[93mRouge_1_F1=0.9724\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.99it/s,        Epoch=21,  \u001b[92mVal Loss=2.5489\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4625\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.74it/s,      Epoch=22,      \u001b[92mLoss=0.0607\u001b[0m,      \u001b[93mRouge_1_F1=0.9808\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.65it/s,        Epoch=22,  \u001b[92mVal Loss=2.6266\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4451\u001b[0m]\n",
            "100%|██████████| 174/174 [00:22<00:00,  7.73it/s,      Epoch=23,      \u001b[92mLoss=0.0426\u001b[0m,      \u001b[93mRouge_1_F1=0.9876\u001b[0m,    LR=0.0001]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.94it/s,        Epoch=23,  \u001b[92mVal Loss=2.5323\u001b[0m,  \u001b[93mVal Rouge_1_F1=0.4740\u001b[0m]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8min 58s, sys: 16.2 s, total: 9min 15s\n",
            "Wall time: 9min 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# train\n",
        "\n",
        "loss_plot, val_loss_plot = [], []\n",
        "lrs = []\n",
        "\n",
        "check_list = []\n",
        "\n",
        "best_val_rouge_1_f1 = 0\n",
        "best_val_loss = 100\n",
        "\n",
        "best_epoch = 0\n",
        "patience = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_rouge_1_f1, total_val_rouge_1_f1 = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader), total=train_dataloader.__len__())\n",
        "    training = True\n",
        "    for batch_idx, batch in tqdm_dataset:\n",
        "        batch_loss, batch_rouge_1_f1, lr = train_step(batch, epoch, training)\n",
        "        total_loss += batch_loss\n",
        "        total_rouge_1_f1 += batch_rouge_1_f1\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            '%+10s' % 'Epoch': epoch + 1,\n",
        "            '%10s' % GREEN + 'Loss' : '{:.4f}'.format(total_loss/(batch_idx+1)) + END,\n",
        "            '%10s' % YELLOW + 'Rouge_1_F1' : '{:.4f}'.format(total_rouge_1_f1/(batch_idx+1)) + END,\n",
        "            '%5s' % 'LR' : lr,\n",
        "        })\n",
        "            \n",
        "    loss_plot.append(total_loss/(batch_idx+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(valid_dataloader), total=valid_dataloader.__len__())\n",
        "    training = False\n",
        "    for batch_idx, batch in tqdm_dataset:\n",
        "        batch_loss, batch_rouge_1_f1 = train_step(batch, epoch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_rouge_1_f1 += batch_rouge_1_f1\n",
        "\n",
        "        tqdm_dataset.set_postfix({\n",
        "            '%+12s' % 'Epoch': epoch + 1,\n",
        "            '%6s' % GREEN + 'Val Loss' : '{:.4f}'.format(total_val_loss/(batch_idx+1)) + END,\n",
        "            '%6s' % YELLOW + 'Val Rouge_1_F1' : '{:.4f}'.format(total_val_rouge_1_f1/(batch_idx+1)) + END,\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch_idx+1)) \n",
        "\n",
        "    cur_val_loss = round(float((total_val_loss/(batch_idx+1)).detach().cpu()), 3)\n",
        "    cur_val_rouge_1_f1 = round(float((total_val_rouge_1_f1/(batch_idx+1))), 3)\n",
        "\n",
        "    # cur_val_loss = round(total_val_loss/(batch_idx+1), 4)\n",
        "    # cur_val_rouge_1_f1 = round(total_val_rouge_1_f1/(batch_idx+1), 4)\n",
        "\n",
        "    # if cur_val_loss < best_val_loss:\n",
        "    if cur_val_rouge_1_f1 > best_val_rouge_1_f1:\n",
        "        print(YELLOW + 'Best_Val_Rouge_1_F1 is updated from {:>5} to {:>5} on epoch {}'.format(best_val_rouge_1_f1, cur_val_rouge_1_f1, epoch+1) + END)\n",
        "        best_val_rouge_1_f1 = cur_val_rouge_1_f1\n",
        "        best_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), './'+save_name+'.ckpt')\n",
        "        if best_epoch > 15:\n",
        "            torch.save(model.state_dict(), './'+save_name+'_loss_{}_val_rouge_1_f1_{}.ckpt'.format(cur_val_loss, cur_val_rouge_1_f1))\n",
        "            patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "    \n",
        "    lrs.append(lr)\n",
        "    \n",
        "    if patience == early_stopping_patience:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9ZwKB-qmLNZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f675b4a-7a98-4f3e-8638-df75925d6df3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerEncoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (word_embedding): Embedding(32500, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (4): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (5): TransformerDecoderLayer(\n",
              "        (self_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attention): AddNorm(\n",
              "          (layer): MultiHeadAttention(\n",
              "            (query_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (scaled_dot_attn): ScaledDotProductAttention()\n",
              "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (feed_forward): AddNorm(\n",
              "          (layer): PoswiseFeedForward(\n",
              "            (feed_forward): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (1): Dropout(p=0.1, inplace=False)\n",
              "              (2): ReLU()\n",
              "              (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=512, out_features=32500, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/Transformer/PyTorch/tft_model.ckpt'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lCOajkIDgCJs"
      },
      "outputs": [],
      "source": [
        "def inference(text, enc_max_len):\n",
        "    enc_inputs = mk_token_inputs(text, enc_max_len).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(enc_inputs)[0]\n",
        "    \n",
        "    outputs = torch.argmax(logits, dim=-1).to('cpu')[0]\n",
        "    outputs = tokenizer.decode(outputs).split(' </s>')[0]\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DmJUg1slNpFO"
      },
      "outputs": [],
      "source": [
        "# text = '오늘 진짜 좋은 일 있었어!'\n",
        "text = '아 슬슬 피곤하네'\n",
        "# text = '잘까? 어떡하지?'\n",
        "# text = '학습 잘 된 걸까?'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference(text, config.max_enc_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GuNG-xRgkmXQ",
        "outputId": "51ce0175-da3e-4f9f-fa0c-9da3c9c5518a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사랑하는 것보다 낫죠.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DHkDG0aUXtGP"
      },
      "outputs": [],
      "source": [
        "def inference(text, max_enc_len):\n",
        "    # enc_token 생성: <string tokens>, [PAD] tokens\n",
        "    enc_token = tokenizer.encode(text, max_length=max_enc_len, padding='max_length')\n",
        "    # dec_token 생성: [BOS], [PAD] tokens\n",
        "    dec_token = [config.bos_id]\n",
        "    dec_token += [0] * (config.max_dec_len - len(dec_token))\n",
        "    dec_token = dec_token[:config.max_dec_len]\n",
        "\n",
        "    response = []\n",
        "    for i in range(config.max_dec_len - 1):\n",
        "        output = model(torch.tensor([enc_token]).to(device), torch.tensor([dec_token]).to(device))[0].detach().cpu().numpy()\n",
        "        word_id = int(np.argmax(output, axis=2)[0][i])\n",
        "\n",
        "        # [EOS] 토큰이 생성되면 종료\n",
        "        if word_id == config.eos_id:\n",
        "            break\n",
        "        # 예측된 token을 응답에 저장\n",
        "        response.append(word_id)\n",
        "        # 예측된 token을 decoder의 다음 입력으로 저장\n",
        "        dec_token[i + 1] = word_id\n",
        "    \n",
        "    return tokenizer.decode(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference(text, config.max_enc_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "90Cpz33DoExR",
        "outputId": "a8e9a6ad-350a-4bcb-b731-1c3ee43313fb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사랑하는 것보다 낫죠.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('종료를 원하실 시에는 exit를 입력해주세요.')\n",
        "while True:\n",
        "    print(\"input > \", end=\"\")\n",
        "    string = str(input())\n",
        "    if string == 'exit':\n",
        "        break\n",
        "    print(f\"output > {inference(string, config.max_enc_len)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqUXzZEIpjaa",
        "outputId": "c8cc2706-0e21-4810-8612-f37c643afc53"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종료를 원하실 시에는 exit를 입력해주세요.\n",
            "input > 안녕하세요\n",
            "output > 안녕하세요.\n",
            "input > 안녕하세요\n",
            "output > 안녕하세요.\n",
            "input > 너는 누구니?\n",
            "output > 저는 위로봇입니다.\n",
            "input > 너는 누구니?\n",
            "output > 저는 위로봇입니다.\n",
            "input > 오늘 너무 피곤해\n",
            "output > 푹 쉬세요.\n",
            "input > 오늘 너무 피곤해\n",
            "output > 푹 쉬세요.\n",
            "input > 와 드디어 쉴 수 있어\n",
            "output > 마음 고생 많았어요.\n",
            "input > 너 똑똑해졌구나?\n",
            "output > 저도 좋아해요.\n",
            "input > 아니 난 안 좋아해\n",
            "output > 사랑했던 사람을 해보세요.\n",
            "input > 뭘 해봐?\n",
            "output > 직접 물어보는 게 좋을 것 같아요.\n",
            "input > 누구한테?\n",
            "output > 저는 마음을 이어주는 위로봇입니다.\n",
            "input > 누구야? 라고 잘못 이해 한거야?\n",
            "output > 저도 궁금하네요.\n",
            "input > 킹받네\n",
            "output > 직접 물어보세요.\n",
            "input > exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVShymqth6pT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "564fb46fe2d043f298fc676037ced098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79257321d69b4eff91ed3ad59ba84fe3",
              "IPY_MODEL_99f129d10c214a0bbdbd44cff92af75f",
              "IPY_MODEL_eccd5c6c0fa040e9b032a895f3e8465f"
            ],
            "layout": "IPY_MODEL_0bcbd8b57b9c41dc93fbc43b0c032f9f"
          }
        },
        "79257321d69b4eff91ed3ad59ba84fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af8b817607148b29b82ce7927fd846b",
            "placeholder": "​",
            "style": "IPY_MODEL_5bc1d950894448faaa1a8d9c7e58882f",
            "value": "Downloading: 100%"
          }
        },
        "99f129d10c214a0bbdbd44cff92af75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f0ae9dab634e85b3017632305d55a9",
            "max": 870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46565c9c6fc74d5bbdc1453950e5647d",
            "value": 870
          }
        },
        "eccd5c6c0fa040e9b032a895f3e8465f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54797ebddf484d2a81e7695ae88e41dd",
            "placeholder": "​",
            "style": "IPY_MODEL_72e45ac7c7d4401bbed6e9b9f6b51a55",
            "value": " 870/870 [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "0bcbd8b57b9c41dc93fbc43b0c032f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af8b817607148b29b82ce7927fd846b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc1d950894448faaa1a8d9c7e58882f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5f0ae9dab634e85b3017632305d55a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46565c9c6fc74d5bbdc1453950e5647d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54797ebddf484d2a81e7695ae88e41dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e45ac7c7d4401bbed6e9b9f6b51a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65a8d0049834c40b59cf778afaf9c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2190d102f7a4f45abb5fd16ca570580",
              "IPY_MODEL_9102c92bd89b468b89cc319335d7ac3e",
              "IPY_MODEL_68398a1731fd4a5daf5dc2faaa40fc81"
            ],
            "layout": "IPY_MODEL_45c6aa0c27d644f486257d109774adcc"
          }
        },
        "b2190d102f7a4f45abb5fd16ca570580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246ba84c79d74d17b21f49f1f33da225",
            "placeholder": "​",
            "style": "IPY_MODEL_bc0bb90f3dbe4da8bbc0807141a92249",
            "value": "Downloading: 100%"
          }
        },
        "9102c92bd89b468b89cc319335d7ac3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b30a8717437444988588ffba3ce294f",
            "max": 241171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8c9d431c69e463083d242b1ea68a532",
            "value": 241171
          }
        },
        "68398a1731fd4a5daf5dc2faaa40fc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee958f453ec4d74b1094c699ebef3b5",
            "placeholder": "​",
            "style": "IPY_MODEL_3015244bc92f47d981e835c55df2a406",
            "value": " 241k/241k [00:00&lt;00:00, 717kB/s]"
          }
        },
        "45c6aa0c27d644f486257d109774adcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246ba84c79d74d17b21f49f1f33da225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0bb90f3dbe4da8bbc0807141a92249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b30a8717437444988588ffba3ce294f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c9d431c69e463083d242b1ea68a532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eee958f453ec4d74b1094c699ebef3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3015244bc92f47d981e835c55df2a406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5973a7e155427e8fea6f6538b82f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6c17f2760d3408cae36b86163774dd1",
              "IPY_MODEL_a81bec6d897d4777a6994fe191216326",
              "IPY_MODEL_78e2523dc74d42e992f2d940b17fb54c"
            ],
            "layout": "IPY_MODEL_f9c171ec61f84d1b9dd6229631917e87"
          }
        },
        "d6c17f2760d3408cae36b86163774dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8590be22b0d54104824dc9d24286404a",
            "placeholder": "​",
            "style": "IPY_MODEL_7eb23dd0171a48b892fce36f5e6c0dec",
            "value": "Downloading: 100%"
          }
        },
        "a81bec6d897d4777a6994fe191216326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c3eae28e0847a48dd253319988f5bb",
            "max": 491774,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_272009d037e14d72987e6e5268e4bebd",
            "value": 491774
          }
        },
        "78e2523dc74d42e992f2d940b17fb54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd62daa2c6747b194f38e8e5a6b5169",
            "placeholder": "​",
            "style": "IPY_MODEL_bee3af92229d4ce19113cd7f9363d453",
            "value": " 492k/492k [00:00&lt;00:00, 664kB/s]"
          }
        },
        "f9c171ec61f84d1b9dd6229631917e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8590be22b0d54104824dc9d24286404a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb23dd0171a48b892fce36f5e6c0dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0c3eae28e0847a48dd253319988f5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "272009d037e14d72987e6e5268e4bebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecd62daa2c6747b194f38e8e5a6b5169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee3af92229d4ce19113cd7f9363d453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46272c31202747c981150a82ea3a9f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57dd16b853ce4628b1c79d8054fd9531",
              "IPY_MODEL_33d4ca9b8d7740f18e37cb7359d7992f",
              "IPY_MODEL_79e9db05873f453db7bd0dc072aa1587"
            ],
            "layout": "IPY_MODEL_846adc4447c6430e8f2734bf842c3332"
          }
        },
        "57dd16b853ce4628b1c79d8054fd9531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dbe00ee63dd47afb06480cdd1d88fc4",
            "placeholder": "​",
            "style": "IPY_MODEL_c1df5292fe8a477991f2c7081294b467",
            "value": "Downloading: 100%"
          }
        },
        "33d4ca9b8d7740f18e37cb7359d7992f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4d25ce6d394311a2d7524cc3b24bd9",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b934495e04cc4956b7899de8670955cd",
            "value": 169
          }
        },
        "79e9db05873f453db7bd0dc072aa1587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd47ae19f9b24d05b154cd274e67e62f",
            "placeholder": "​",
            "style": "IPY_MODEL_49f1118a9b7b45f7a07b5619e025833b",
            "value": " 169/169 [00:00&lt;00:00, 6.75kB/s]"
          }
        },
        "846adc4447c6430e8f2734bf842c3332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dbe00ee63dd47afb06480cdd1d88fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1df5292fe8a477991f2c7081294b467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4d25ce6d394311a2d7524cc3b24bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b934495e04cc4956b7899de8670955cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd47ae19f9b24d05b154cd274e67e62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f1118a9b7b45f7a07b5619e025833b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573dfdf1f7044d13aa2746ea5881b9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b50e14a25e0428cb8a1e37c7014d13c",
              "IPY_MODEL_822383b1670f4b21b0d2ba4319a67421",
              "IPY_MODEL_2793fd715b804cf993723e1a13adc75b"
            ],
            "layout": "IPY_MODEL_593c6ca3faba4b8a8b798df2bfdfbfbe"
          }
        },
        "3b50e14a25e0428cb8a1e37c7014d13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02258a4ba96c4c57ae6bcb8c3a0435cc",
            "placeholder": "​",
            "style": "IPY_MODEL_b3ca82a0ec4b484399fa2c7a785baa11",
            "value": "Downloading: 100%"
          }
        },
        "822383b1670f4b21b0d2ba4319a67421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8307a4bffc4d998501c85d7bbde439",
            "max": 373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07476a9d9b884784850fe6b2d72ad3a0",
            "value": 373
          }
        },
        "2793fd715b804cf993723e1a13adc75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_839df2a601d14b1aac40f99d46582e69",
            "placeholder": "​",
            "style": "IPY_MODEL_9486cfb6779341a19f8f00f852e986b2",
            "value": " 373/373 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "593c6ca3faba4b8a8b798df2bfdfbfbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02258a4ba96c4c57ae6bcb8c3a0435cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ca82a0ec4b484399fa2c7a785baa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8307a4bffc4d998501c85d7bbde439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07476a9d9b884784850fe6b2d72ad3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "839df2a601d14b1aac40f99d46582e69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9486cfb6779341a19f8f00f852e986b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}